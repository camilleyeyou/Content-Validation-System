"""
Validation Orchestrator - Updated to use persona-based validators with dedicated ImageGenerationAgent
Manages the complete validation workflow with Sarah, Marcus, and Jordan personas
FIXED: Images now generated by dedicated agent and preserved through revisions
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
from datetime import datetime
import structlog

from src.domain.models.post import LinkedInPost, PostStatus, ValidationScore
from src.domain.models.batch import Batch, BatchMetrics
from src.domain.agents.base_agent import BaseAgent
from src.domain.agents.advanced_content_generator import AdvancedContentGenerator
from src.domain.agents.image_generation_agent import ImageGenerationAgent
from src.domain.agents.validators.sarah_chen_validator import SarahChenValidator
from src.domain.agents.validators.marcus_williams_validator import MarcusWilliamsValidator
from src.domain.agents.validators.jordan_park_validator import JordanParkValidator
from src.domain.agents.feedback_aggregator import FeedbackAggregator
from src.domain.agents.revision_generator import RevisionGenerator
from src.infrastructure.config.config_manager import AppConfig

logger = structlog.get_logger()

class ValidationOrchestrator:
    """Orchestrates the validation workflow with persona-based parallel processing and dedicated image generation"""
    
    def __init__(self,
                 content_generator: AdvancedContentGenerator,
                 validators: List[BaseAgent],
                 feedback_aggregator: FeedbackAggregator,
                 revision_generator: RevisionGenerator,
                 image_generator: ImageGenerationAgent,
                 config: AppConfig):
        self.content_generator = content_generator
        self.validators = validators
        self.feedback_aggregator = feedback_aggregator
        self.revision_generator = revision_generator
        self.image_generator = image_generator  # NEW: Dedicated image agent
        self.config = config
        self.logger = logger.bind(component="orchestrator")
        
        # Performance tracking
        self._total_posts_processed = 0
        self._total_approvals = 0
        self._total_revisions = 0
        self._total_rejections = 0
        
        # Track persona agreement patterns
        self._persona_agreements = {
            "all_three": 0,
            "two_of_three": 0,
            "one_of_three": 0,
            "none": 0
        }
    
    async def process_batch(self, batch_size: Optional[int] = None) -> Batch:
        """Process a batch of posts through the complete workflow"""
        batch_size = batch_size or self.config.batch.posts_per_batch
        batch = Batch()
        
        self.logger.info("batch_processing_started", 
                        batch_id=batch.id, 
                        size=batch_size,
                        validators=["SarahChen", "MarcusWilliams", "JordanPark"])
        
        try:
            # Step 1: Generate initial posts WITH images
            posts = await self._generate_initial_posts(batch.id, batch_size)
            for post in posts:
                batch.add_post(post)
            
            # Step 2: Process each post through validation pipeline
            for post in batch.posts:
                await self._process_single_post(post)
            
            # Step 3: Check if we need regeneration
            approval_rate = self._calculate_approval_rate(batch.posts)
            
            if approval_rate < self.config.batch.target_approval_rate:
                self.logger.info("batch_regeneration_needed",
                               approval_rate=approval_rate,
                               target=self.config.batch.target_approval_rate)
                
                # Analyze failures and regenerate
                additional_posts = await self._handle_regeneration(
                    batch, 
                    batch_size
                )
                
                # Process regenerated posts
                for post in additional_posts:
                    batch.add_post(post)
                    await self._process_single_post(post)
            
            # Step 4: Complete batch and calculate metrics
            batch.complete()
            
            # Update orchestrator stats
            self._update_statistics(batch)
            
            self.logger.info("batch_processing_completed",
                           batch_id=batch.id,
                           approved=batch.metrics.approved_posts,
                           rejected=batch.metrics.rejected_posts,
                           posts_with_images=batch.metrics.posts_with_images,
                           approval_rate=batch.metrics.approval_rate,
                           persona_agreement_rate=self._calculate_persona_agreement_rate())
            
            return batch
            
        except Exception as e:
            batch.status = "failed"
            batch.error = str(e)
            self.logger.error("batch_processing_failed", 
                            batch_id=batch.id, 
                            error=str(e))
            raise
    
    async def _process_single_post(self, post: LinkedInPost) -> LinkedInPost:
        """Process a single post through validation with persona-based approval"""
        start_time = time.time()
        post.status = PostStatus.VALIDATING
        
        self.logger.info("post_processing_started", 
                        post_id=post.id,
                        batch_id=post.batch_id,
                        has_image=bool(post.image_url))
        
        # Keep trying until approved or max revisions reached
        while True:
            # Step 1: Validate with all three personas in parallel
            validation_scores = await self._validate_post_parallel(post)
            
            # Clear old scores and add new ones
            post.validation_scores = []
            for score in validation_scores:
                post.add_validation(score)
            
            # Track persona agreement
            self._track_persona_agreement(validation_scores)
            
            # Step 2: Check approval status (requires 2/3 personas to approve)
            approved_count = sum(1 for score in validation_scores if score.approved)
            post_approved = approved_count >= 2  # At least 2 out of 3 must approve
            
            if post_approved:
                post.status = PostStatus.APPROVED
                post.processing_time_seconds = time.time() - start_time
                
                self.logger.info("post_approved",
                               post_id=post.id,
                               approval_count=approved_count,
                               average_score=post.average_score,
                               has_image=bool(post.image_url),
                               personas_approved=[s.agent_name for s in validation_scores if s.approved])
                break
            
            # Step 3: Check if we can revise
            if post.can_revise():
                self.logger.info("post_revision_needed",
                               post_id=post.id,
                               revision_count=post.revision_count,
                               average_score=post.average_score,
                               lowest_scorer=min(validation_scores, key=lambda x: x.score).agent_name)
                
                # Aggregate feedback focusing on lowest scorer
                feedback = await self._aggregate_persona_feedback(post, validation_scores)
                
                # Store image data before revision
                original_image_url = post.image_url
                original_image_prompt = post.image_prompt
                original_image_description = post.image_description
                original_image_revised_prompt = post.image_revised_prompt
                
                # Revise the post
                revised_post = await self.revision_generator.process((post, feedback))
                post = revised_post
                post.status = PostStatus.REVISION_NEEDED
                
                # CRITICAL: Restore image data after revision
                if original_image_url and not post.image_url:
                    self.logger.info("Restoring image data after revision", post_id=post.id)
                    post.set_image(
                        url=original_image_url,
                        prompt=original_image_prompt,
                        description=original_image_description,
                        revised_prompt=original_image_revised_prompt
                    )
                
                # Continue loop to re-validate
                continue
            else:
                # Max revisions reached, reject
                post.status = PostStatus.REJECTED
                post.processing_time_seconds = time.time() - start_time
                
                self.logger.info("post_rejected",
                               post_id=post.id,
                               revision_count=post.revision_count,
                               average_score=post.average_score,
                               all_scores={s.agent_name: s.score for s in validation_scores})
                break
        
        return post
    
    async def _validate_post_parallel(self, post: LinkedInPost) -> List[ValidationScore]:
        """Validate a post with all three personas in parallel"""
        validation_tasks = []
        
        for validator in self.validators:
            task = asyncio.create_task(validator.process(post))
            validation_tasks.append(task)
        
        # Wait for all validators to complete
        validation_scores = await asyncio.gather(*validation_tasks)
        
        self.logger.debug("parallel_validation_completed",
                         post_id=post.id,
                         scores={score.agent_name: score.score for score in validation_scores})
        
        return validation_scores
    
    async def _aggregate_persona_feedback(self, post: LinkedInPost, scores: List[ValidationScore]) -> Dict[str, Any]:
        """Aggregate feedback with focus on persona-specific concerns"""
        # Find the lowest scorer for targeted improvements
        lowest_score = min(scores, key=lambda x: x.score)
        
        # Get standard aggregated feedback
        base_feedback = await self.feedback_aggregator.process(post)
        
        # Add persona-specific guidance
        persona_guidance = {
            "lowest_scorer": lowest_score.agent_name,
            "persona_specific_fixes": {}
        }
        
        for score in scores:
            if not score.approved:
                if score.agent_name == "SarahChen":
                    persona_guidance["persona_specific_fixes"]["sarah"] = {
                        "focus": "authenticity and daily pain points",
                        "fix": "Make it feel less like marketing, more like shared experience",
                        "key_barrier": score.criteria_breakdown.get("barrier_addressed", "none")
                    }
                elif score.agent_name == "MarcusWilliams":
                    persona_guidance["persona_specific_fixes"]["marcus"] = {
                        "focus": "scalability and ROI",
                        "fix": "Show how this becomes a campaign, not just a post",
                        "key_concern": score.criteria_breakdown.get("risk_assessment", "neutral")
                    }
                elif score.agent_name == "JordanPark":
                    persona_guidance["persona_specific_fixes"]["jordan"] = {
                        "focus": "platform mechanics and virality",
                        "fix": "Strengthen hook and add share trigger",
                        "engagement_prediction": score.criteria_breakdown.get("engagement_prediction", "moderate")
                    }
        
        # Merge with base feedback
        base_feedback["persona_guidance"] = persona_guidance
        
        return base_feedback
    
    def _track_persona_agreement(self, scores: List[ValidationScore]) -> None:
        """Track how often personas agree on content"""
        approved_count = sum(1 for score in scores if score.approved)
        
        if approved_count == 3:
            self._persona_agreements["all_three"] += 1
        elif approved_count == 2:
            self._persona_agreements["two_of_three"] += 1
        elif approved_count == 1:
            self._persona_agreements["one_of_three"] += 1
        else:
            self._persona_agreements["none"] += 1
    
    def _calculate_persona_agreement_rate(self) -> float:
        """Calculate how often at least 2 personas agree"""
        total = sum(self._persona_agreements.values())
        if total == 0:
            return 0.0
        
        agreements = self._persona_agreements["all_three"] + self._persona_agreements["two_of_three"]
        return agreements / total
    
    async def _generate_initial_posts(self, batch_id: str, count: int) -> List[LinkedInPost]:
        """Generate initial batch of posts and attach images using ImageGenerationAgent"""
        input_data = {
            "batch_id": batch_id,
            "count": count,
            "brand_context": {
                "product": self.config.brand.product_name,
                "price": self.config.brand.price,
                "tagline": self.config.brand.tagline,
                "audience": self.config.brand.target_audience
            }
        }
        
        generated_data = await self.content_generator.process(input_data)
        
        # Convert to LinkedInPost objects (without worrying about images)
        posts = []
        for post_data in generated_data:
            post = LinkedInPost(
                batch_id=batch_id,
                post_number=post_data.get("post_number", len(posts) + 1),
                content=post_data["content"],
                target_audience=post_data.get("target_audience", "LinkedIn professionals"),
                cultural_reference=post_data.get("cultural_reference"),
                hashtags=post_data.get("hashtags", [])
            )
            posts.append(post)
        
        self.logger.info("initial_posts_generated",
                        batch_id=batch_id,
                        count=len(posts))
        
        # NEW: Generate images for all posts using dedicated ImageGenerationAgent
        await self._attach_images_to_posts(posts)
        
        # Log final stats
        posts_with_images = sum(1 for p in posts if p.image_url)
        self.logger.info("images_attached_to_posts",
                        batch_id=batch_id,
                        posts_with_images=posts_with_images,
                        image_generation_rate=f"{posts_with_images}/{len(posts)}")
        
        return posts
    
    async def _attach_images_to_posts(self, posts: List[LinkedInPost]) -> None:
        """Generate images for all posts using ImageGenerationAgent"""
        for post in posts:
            try:
                self.logger.info("Generating image for post", post_id=post.id)
                await self.image_generator.process(post)
            except Exception as e:
                self.logger.error(f"Failed to attach image to post {post.id}: {e}")
    
    async def _handle_regeneration(self, batch: Batch, target_count: int) -> List[LinkedInPost]:
        """Handle regeneration with persona-specific failure analysis"""
        rejected_posts = batch.get_rejected_posts()
        
        if not rejected_posts:
            return []
        
        # Analyze failure patterns by persona
        failure_patterns = self._analyze_persona_failures(rejected_posts)
        
        # Calculate how many more posts we need
        approved_count = len(batch.get_approved_posts())
        needed_count = max(1, target_count - approved_count)
        
        # Generate new posts avoiding failure patterns
        input_data = {
            "batch_id": batch.id,
            "count": needed_count,
            "brand_context": {
                "product": self.config.brand.product_name,
                "price": self.config.brand.price,
                "tagline": self.config.brand.tagline,
                "audience": self.config.brand.target_audience
            },
            "avoid_patterns": failure_patterns
        }
        
        generated_data = await self.content_generator.process(input_data)
        
        # Convert to LinkedInPost objects
        new_posts = []
        for post_data in generated_data:
            post = LinkedInPost(
                batch_id=batch.id,
                post_number=len(batch.posts) + len(new_posts) + 1,
                content=post_data["content"],
                target_audience=post_data.get("target_audience", "LinkedIn professionals"),
                cultural_reference=post_data.get("cultural_reference"),
                hashtags=post_data.get("hashtags", [])
            )
            new_posts.append(post)
        
        # Generate images for regenerated posts
        await self._attach_images_to_posts(new_posts)
        
        posts_with_images = sum(1 for p in new_posts if p.image_url)
        
        self.logger.info("regenerated_posts",
                        batch_id=batch.id,
                        count=len(new_posts),
                        posts_with_images=posts_with_images,
                        avoiding_patterns=list(failure_patterns.keys()))
        
        return new_posts
    
    def _analyze_persona_failures(self, rejected_posts: List[LinkedInPost]) -> Dict[str, Any]:
        """Analyze failure patterns by persona"""
        patterns = {
            "sarah_issues": [],
            "marcus_issues": [],
            "jordan_issues": [],
            "cultural_references_failed": [],
            "common_feedback": []
        }
        
        for post in rejected_posts:
            for score in post.validation_scores:
                if not score.approved:
                    if score.agent_name == "SarahChen":
                        if score.criteria_breakdown.get("barrier_addressed") == "expensive chapstick":
                            patterns["sarah_issues"].append("price_justification")
                        if score.criteria_breakdown.get("authenticity_score", 0) < 5:
                            patterns["sarah_issues"].append("too_corporate")
                    
                    elif score.agent_name == "MarcusWilliams":
                        if score.criteria_breakdown.get("scalability") == "one-off":
                            patterns["marcus_issues"].append("not_scalable")
                        if score.criteria_breakdown.get("risk_assessment") == "career-limiting":
                            patterns["marcus_issues"].append("too_risky")
                    
                    elif score.agent_name == "JordanPark":
                        if score.criteria_breakdown.get("hook_strength", 0) < 5:
                            patterns["jordan_issues"].append("weak_hook")
                        if score.criteria_breakdown.get("meme_timing") in ["dead", "late"]:
                            patterns["jordan_issues"].append("outdated_references")
                    
                    patterns["common_feedback"].append(score.feedback)
            
            # Track failed cultural references
            if post.cultural_reference:
                patterns["cultural_references_failed"].append(post.cultural_reference.reference)
        
        # Keep only unique values
        for key in patterns:
            if isinstance(patterns[key], list):
                patterns[key] = list(set(patterns[key]))[:3]  # Keep top 3
        
        return patterns
    
    def _calculate_approval_rate(self, posts: List[LinkedInPost]) -> float:
        """Calculate the approval rate for a list of posts"""
        if not posts:
            return 0.0
        
        approved = sum(1 for p in posts if p.status == PostStatus.APPROVED)
        return approved / len(posts)
    
    def _update_statistics(self, batch: Batch) -> None:
        """Update orchestrator statistics"""
        self._total_posts_processed += batch.metrics.total_posts
        self._total_approvals += batch.metrics.approved_posts
        self._total_rejections += batch.metrics.rejected_posts
        self._total_revisions += batch.metrics.revised_posts
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get orchestrator statistics including persona insights"""
        return {
            "total_posts_processed": self._total_posts_processed,
            "total_approvals": self._total_approvals,
            "total_rejections": self._total_rejections,
            "total_revisions": self._total_revisions,
            "overall_approval_rate": self._total_approvals / self._total_posts_processed 
                if self._total_posts_processed > 0 else 0,
            "revision_effectiveness": self._total_revisions / self._total_posts_processed
                if self._total_posts_processed > 0 else 0,
            "persona_agreement_patterns": self._persona_agreements,
            "persona_agreement_rate": self._calculate_persona_agreement_rate()
        }